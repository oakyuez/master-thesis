{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.utils import shuffle, resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"/home/jupyter-ozkan_ma/data/CSV/news_preprocessed_with_addtionalLabel.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same train and test data\n",
    "def split_df_in_train_test(df):\n",
    "    df = df.reset_index()\n",
    "    split_point = int(np.round(df.shape[0]) * 0.8)\n",
    "    df_train = df.loc[:split_point-1,:]\n",
    "    df_test = df.loc[split_point:,:]\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_AbSt_01 = resample(shuffle(news[(news[\"Label_AbStudy_01\"]==\"Left\") & (news[\"Length\"]<512)], random_state=42), \\\n",
    "         random_state=42, n_samples=25000)\n",
    "center_AbSt_01 = resample(shuffle(news[(news[\"Label_AbStudy_01\"]==\"Center\") & (news[\"Length\"]<512)], random_state=42), \\\n",
    "         random_state=42, n_samples=25000)\n",
    "right_AbSt_01 = resample(shuffle(news[(news[\"Label_AbStudy_01\"]==\"Right\") & (news[\"Length\"]<512)], random_state=42), \\\n",
    "         random_state=42, n_samples=25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([split_df_in_train_test(left_AbSt_01)[0], \\\n",
    "    split_df_in_train_test(center_AbSt_01)[0], \\\n",
    "    split_df_in_train_test(right_AbSt_01)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([split_df_in_train_test(left_AbSt_01)[1], \\\n",
    "    split_df_in_train_test(center_AbSt_01)[1], \\\n",
    "    split_df_in_train_test(right_AbSt_01)[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train[\"pre_content_str\"], train[\"Label_AbStudy_01\"]\n",
    "X_test, y_test = test[\"pre_content_str\"], test[\"Label_AbStudy_01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate trigram tfidf vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_vec = TfidfVectorizer(stop_words=\"english\", max_features=30000, ngram_range=(1, 3))\n",
    "\n",
    "X_train_tri = trigram_vec.fit_transform(X_train.apply(lambda x: np.str_(x)))\n",
    "X_test_tri = trigram_vec.transform(X_test.apply(lambda x: np.str_(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc = LabelEncoder()\n",
    "y_train_enc = label_enc.fit_transform(y_train)\n",
    "y_test_enc = label_enc.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Center', 'Left', 'Right'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enc.inverse_transform([0, 1, 2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [0, 1, 2]\n",
    "target_label = [\"Center\", \"Left\", \"Right\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to run and evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(clf, X_train, X_test, y_train, y_test, label, target_label):\n",
    "    \n",
    "    print(\"Training of the classifier: {} \\n\".format(clf))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Accuracy of the classifier:     \")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Confusion Matrix of the classifier: \\n\")\n",
    "    con_mat = confusion_matrix(y_test, y_pred, labels=label)\n",
    "    print(con_mat)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Classification Report of the classifier: \\n\")\n",
    "    report = classification_report(y_test, y_pred, target_names=target_label)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of the classifier: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) \n",
      "\n",
      "\n",
      "\n",
      "Accuracy of the classifier:     \n",
      "0.7419333333333333\n",
      "\n",
      "\n",
      "Confusion Matrix of the classifier: \n",
      "\n",
      "[[3758  629  613]\n",
      " [ 552 3752  696]\n",
      " [ 706  675 3619]]\n",
      "\n",
      "\n",
      "Classification Report of the classifier: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Center       0.75      0.75      0.75      5000\n",
      "        Left       0.74      0.75      0.75      5000\n",
      "       Right       0.73      0.72      0.73      5000\n",
      "\n",
      "    accuracy                           0.74     15000\n",
      "   macro avg       0.74      0.74      0.74     15000\n",
      "weighted avg       0.74      0.74      0.74     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classifier(svc, X_train_tri, X_test_tri, y_train_enc, y_test_enc, label, target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-oezkan_thesis]",
   "language": "python",
   "name": "conda-env-.conda-oezkan_thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
